{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Install libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download fr_core_news_sm\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:30:01.617841Z",
     "start_time": "2023-12-03T21:30:00.026717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.training.example import Example\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:47:29.576604Z",
     "start_time": "2024-01-19T14:47:03.160396Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load spaCy model and add NER labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:28:34.988112Z",
     "start_time": "2023-12-03T21:28:29.269969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')\n",
    "ner = nlp.get_pipe('ner')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:47:49.894854Z",
     "start_time": "2024-01-19T14:47:41.922927Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "label_names = [\"departure\", \"arrival\", \"transit\", \"departure_day\", \"departure_date\", \"departure_time\"]\n",
    "\n",
    "for label_name in label_names:\n",
    "    ner.add_label(label_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:47:52.149358Z",
     "start_time": "2024-01-19T14:47:52.122386Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "               transit departure_day departure_time departure_date  \\\n0            Beaugency          None           None           None   \n1                 None         mardi          19h39        1 avril   \n2  Les Sables-d'Olonne          None           None           None   \n3            Écouflant          None           None           None   \n4              Le Toec      dimanche          23h37         25 mai   \n\n                                            sentence            departure  \\\n0  Je mets le cap sur Tieffenbach-Struth en parta...      Paris-St-Lazare   \n1  Est-ce possible d'aller de Lafarge à Sannois l...              Lafarge   \n2  Mon itinéraire prévu est de Trouville-Deauvill...  Trouville-Deauville   \n3  Je traverse Écouflant en me rendant de Gunsbac...   Gunsbach-Griesbach   \n4  Je planifie de démarrer de Portets  le dimanch...              Portets   \n\n              arrival  \n0  Tieffenbach-Struth  \n1             Sannois  \n2            Argentan  \n3               Ugine  \n4             Nurieux  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transit</th>\n      <th>departure_day</th>\n      <th>departure_time</th>\n      <th>departure_date</th>\n      <th>sentence</th>\n      <th>departure</th>\n      <th>arrival</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beaugency</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Je mets le cap sur Tieffenbach-Struth en parta...</td>\n      <td>Paris-St-Lazare</td>\n      <td>Tieffenbach-Struth</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n      <td>mardi</td>\n      <td>19h39</td>\n      <td>1 avril</td>\n      <td>Est-ce possible d'aller de Lafarge à Sannois l...</td>\n      <td>Lafarge</td>\n      <td>Sannois</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Les Sables-d'Olonne</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Mon itinéraire prévu est de Trouville-Deauvill...</td>\n      <td>Trouville-Deauville</td>\n      <td>Argentan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Écouflant</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Je traverse Écouflant en me rendant de Gunsbac...</td>\n      <td>Gunsbach-Griesbach</td>\n      <td>Ugine</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Le Toec</td>\n      <td>dimanche</td>\n      <td>23h37</td>\n      <td>25 mai</td>\n      <td>Je planifie de démarrer de Portets  le dimanch...</td>\n      <td>Portets</td>\n      <td>Nurieux</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../data/transport_french.json\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df_data, df_data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:48:02.833044Z",
     "start_time": "2024-01-19T14:48:02.703201Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "('mon itinéraire prévu est de bellegarde à dreuil-lès-amiens, avec un arrêt à givors.',\n {'entities': [(28, 38, 'departure'),\n   (41, 58, 'arrival'),\n   (76, 82, 'transit')]})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "\n",
    "for index, row in df_data.iterrows():\n",
    "    sentence = row[\"sentence\"].lower()\n",
    "\n",
    "    entities = [\n",
    "        (\"departure\", row[\"departure\"]),\n",
    "        (\"arrival\", row[\"arrival\"]),\n",
    "        (\"transit\", row[\"transit\"]),\n",
    "        (\"departure_day\", row[\"departure_day\"]),\n",
    "        (\"departure_date\", row[\"departure_date\"]),\n",
    "        (\"departure_time\", row[\"departure_time\"]),\n",
    "    ]\n",
    "\n",
    "    annotations = {\"entities\": []}\n",
    "\n",
    "    for entity_label, entity_text in entities:\n",
    "        if entity_text:\n",
    "            start_pos = sentence.find(entity_text.lower())\n",
    "            end_pos = start_pos + len(entity_text)\n",
    "            if not any(start <= start_pos < end or start < end_pos <= end for start, end, _ in annotations[\"entities\"]):\n",
    "                annotations[\"entities\"].append((start_pos, end_pos, entity_label))\n",
    "\n",
    "    train_data.append((sentence, annotations))\n",
    "\n",
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:48:11.018820Z",
     "start_time": "2024-01-19T14:48:09.838545Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    nlp.update([example], drop=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:53:27.001867Z",
     "start_time": "2024-01-19T14:49:06.033738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model_path = \"../model/ner_transport_model\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    nlp.to_disk(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T14:53:41.814361Z",
     "start_time": "2024-01-19T14:53:41.319485Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.40%\n"
     ]
    }
   ],
   "source": [
    "my_nlp = spacy.load(\"../model/ner_transport_model\")\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = len(df_data_test)\n",
    "\n",
    "for _, row in df_data_test.iterrows():\n",
    "    my_doc = my_nlp(row[\"sentence\"])\n",
    "\n",
    "    is_prediction_true = all(\n",
    "        ent is None or getattr(ent, 'text', '').lower() == str(row[ent.label_]).lower()\n",
    "        for ent in my_doc.ents\n",
    "    )\n",
    "\n",
    "    correct_predictions += is_prediction_true\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T15:01:53.130272Z",
     "start_time": "2024-01-19T15:01:37.489262Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity : mercredi, Label : departure_day\n",
      "Entity : 27 novembre, Label : departure_date\n",
      "Entity : paris, Label : departure\n",
      "Entity : marseille, Label : arrival\n",
      "Entity : 9h, Label : departure_time\n",
      "Entity : lyon, Label : transit\n"
     ]
    }
   ],
   "source": [
    "my_nlp = spacy.load(\"../model/ner_transport_model\")\n",
    "\n",
    "text = \"le mercredi 27 novembre, je pars de paris pour marseille à 9h, en passant par lyon\"\n",
    "\n",
    "# Process sample text with the trained model\n",
    "doc = my_nlp(text)\n",
    "\n",
    "# Display named entities in the processed text\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity : {ent.text}, Label : {ent.label_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T15:05:42.751657Z",
     "start_time": "2024-01-19T15:05:40.932367Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
