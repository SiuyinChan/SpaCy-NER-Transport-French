{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download fr_core_news_sm\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:30:01.617841Z",
     "start_time": "2023-12-03T21:30:00.026717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.training.example import Example\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:32:54.128748Z",
     "start_time": "2023-12-03T21:32:54.121452Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load spaCy model and add NER labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:28:34.988112Z",
     "start_time": "2023-12-03T21:28:29.269969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')\n",
    "ner = nlp.get_pipe('ner')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:33:04.630220Z",
     "start_time": "2023-12-03T21:32:56.463286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.add_label(\"departure\")\n",
    "ner.add_label(\"arrival\")\n",
    "ner.add_label(\"transit\")\n",
    "ner.add_label(\"departure_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:33:06.015620Z",
     "start_time": "2023-12-03T21:33:05.975758Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                     transit departure_time  \\\n0                      Melun       mercredi   \n1                      Mézin         samedi   \n2                  Aimargues           None   \n3                       None       dimanche   \n4  Feuquières-Fressenneville           None   \n\n                                            sentence          departure  \\\n0  Je réserve un billet de St-Thégonnec à St-Andr...       St-Thégonnec   \n1  Je traverse Mézin en me rendant de Courtenay à...          Courtenay   \n2  Je cherche un itinéraire de Rougebarre à Clell...         Rougebarre   \n3   Je me rends dimanche de Mézy à Lille-St-Sauveur.               Mézy   \n4  Tournon-St-Martin est mon point de départ, je ...  Tournon-St-Martin   \n\n                    arrival  \n0        St-André-de-Cubzac  \n1  Ste-Eulalie-Carbon-Blanc  \n2              Clelles-Mens  \n3          Lille-St-Sauveur  \n4                 Turckheim  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transit</th>\n      <th>departure_time</th>\n      <th>sentence</th>\n      <th>departure</th>\n      <th>arrival</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Melun</td>\n      <td>mercredi</td>\n      <td>Je réserve un billet de St-Thégonnec à St-Andr...</td>\n      <td>St-Thégonnec</td>\n      <td>St-André-de-Cubzac</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mézin</td>\n      <td>samedi</td>\n      <td>Je traverse Mézin en me rendant de Courtenay à...</td>\n      <td>Courtenay</td>\n      <td>Ste-Eulalie-Carbon-Blanc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aimargues</td>\n      <td>None</td>\n      <td>Je cherche un itinéraire de Rougebarre à Clell...</td>\n      <td>Rougebarre</td>\n      <td>Clelles-Mens</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>None</td>\n      <td>dimanche</td>\n      <td>Je me rends dimanche de Mézy à Lille-St-Sauveur.</td>\n      <td>Mézy</td>\n      <td>Lille-St-Sauveur</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Feuquières-Fressenneville</td>\n      <td>None</td>\n      <td>Tournon-St-Martin est mon point de départ, je ...</td>\n      <td>Tournon-St-Martin</td>\n      <td>Turckheim</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../data/transport_french.json\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df_data, df_data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:33:28.325846Z",
     "start_time": "2023-12-03T21:33:28.203367Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "('Je me rends de Pierre-Buffière à La Joux.',\n {'entities': [(15, 30, 'departure'), (33, 40, 'arrival')]})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "\n",
    "for index, row in df_data.iterrows():\n",
    "    sentence = row[\"sentence\"]\n",
    "    departure = row[\"departure\"]\n",
    "    arrival = row[\"arrival\"]\n",
    "    transit = row[\"transit\"]\n",
    "    departure_time = row[\"departure_time\"]\n",
    "\n",
    "    annotations = {\"entities\": []}\n",
    "\n",
    "    # Define annotations for named entities\n",
    "    if departure:\n",
    "        start_pos = sentence.find(departure)\n",
    "        end_pos = start_pos + len(departure)\n",
    "        annotations[\"entities\"].append((start_pos, end_pos, \"departure\"))\n",
    "\n",
    "    if arrival:\n",
    "        start_pos = sentence.find(arrival)\n",
    "        end_pos = start_pos + len(arrival)\n",
    "        # Check for overlap with existing entities\n",
    "        if not any(start <= start_pos < end or start < end_pos <= end for start, end, _ in annotations[\"entities\"]):\n",
    "            annotations[\"entities\"].append((start_pos, end_pos, \"arrival\"))\n",
    "\n",
    "    if transit:\n",
    "        start_pos = sentence.find(transit)\n",
    "        end_pos = start_pos + len(transit)\n",
    "        if not any(start <= start_pos < end or start < end_pos <= end for start, end, _ in annotations[\"entities\"]):\n",
    "            annotations[\"entities\"].append((start_pos, end_pos, \"transit\"))\n",
    "\n",
    "    if departure_time:\n",
    "        start_pos = sentence.find(departure_time)\n",
    "        end_pos = start_pos + len(departure_time)\n",
    "        annotations[\"entities\"].append((start_pos, end_pos, \"departure_time\"))\n",
    "\n",
    "    train_data.append((sentence, annotations))\n",
    "\n",
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:33:35.824338Z",
     "start_time": "2023-12-03T21:33:34.857743Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    nlp.update([example], drop=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:39:16.239329Z",
     "start_time": "2023-12-03T21:33:51.347547Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model_path = \"../model/ner_transport_model\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    nlp.to_disk(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:42:07.720955Z",
     "start_time": "2023-12-03T21:42:07.717483Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "my_nlp = spacy.load(\"../model/ner_transport_model\")\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for index, row in df_data_test.iterrows():\n",
    "    my_doc = my_nlp(row[\"sentence\"])\n",
    "    isPredictionTrue = True\n",
    "    for ent in my_doc.ents:\n",
    "        if ent.label_ == \"departure\" and ent.text != row[\"departure\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"arrival\" and ent.text != row[\"arrival\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"transit\" and ent.text != row[\"transit\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"departure_time\" and ent.text != row[\"departure_time\"]:\n",
    "            isPredictionTrue = False\n",
    "    if isPredictionTrue:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    total_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T21:59:13.344342Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity : Lyon, Label : transit\n",
      "Entity : Paris, Label : departure\n",
      "Entity : Marseille, Label : arrival\n",
      "Entity : 27 novembre à 9h, Label : departure_time\n"
     ]
    }
   ],
   "source": [
    "my_nlp = spacy.load(\"../model/ner_transport_model\")\n",
    "\n",
    "text = \"en passant par Lyon, je pars de Paris le 27 novembre à 9h pour Marseille\"\n",
    "\n",
    "# Process sample text with the trained model\n",
    "doc = my_nlp(text)\n",
    "\n",
    "# Display named entities in the processed text\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity : {ent.text}, Label : {ent.label_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T22:00:37.640081Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
