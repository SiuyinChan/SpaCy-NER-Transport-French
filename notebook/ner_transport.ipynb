{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download fr_core_news_sm\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:30:01.617841Z",
     "start_time": "2023-12-03T21:30:00.026717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.training.example import Example\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:15:59.133332Z",
     "start_time": "2023-12-08T14:15:35.228404Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load spaCy model and add NER labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T21:28:34.988112Z",
     "start_time": "2023-12-03T21:28:29.269969Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_sm')\n",
    "ner = nlp.get_pipe('ner')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:16:11.197747Z",
     "start_time": "2023-12-08T14:16:04.619713Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.add_label(\"departure\")\n",
    "ner.add_label(\"arrival\")\n",
    "ner.add_label(\"transit\")\n",
    "ner.add_label(\"departure_day\")\n",
    "ner.add_label(\"departure_date\")\n",
    "ner.add_label(\"departure_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:16:27.079332Z",
     "start_time": "2023-12-08T14:16:27.021857Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "               transit departure_day departure_time departure_date  \\\n0            Beaugency          None           None           None   \n1                 None         mardi         19h 39        1 avril   \n2  Les Sables-d'Olonne          None           None           None   \n3            Écouflant          None           None           None   \n4              Le Toec      dimanche         23h 37         25 mai   \n\n                                            sentence            departure  \\\n0  Je mets le cap sur Tieffenbach-Struth en parta...      Paris-St-Lazare   \n1  Est-ce possible d'aller de Lafarge à Sannois l...              Lafarge   \n2  Mon itinéraire prévu est de Trouville-Deauvill...  Trouville-Deauville   \n3  Je traverse Écouflant en me rendant de Gunsbac...   Gunsbach-Griesbach   \n4  Je planifie de démarrer de Portets  le dimanch...              Portets   \n\n              arrival  \n0  Tieffenbach-Struth  \n1             Sannois  \n2            Argentan  \n3               Ugine  \n4             Nurieux  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transit</th>\n      <th>departure_day</th>\n      <th>departure_time</th>\n      <th>departure_date</th>\n      <th>sentence</th>\n      <th>departure</th>\n      <th>arrival</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beaugency</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Je mets le cap sur Tieffenbach-Struth en parta...</td>\n      <td>Paris-St-Lazare</td>\n      <td>Tieffenbach-Struth</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>None</td>\n      <td>mardi</td>\n      <td>19h 39</td>\n      <td>1 avril</td>\n      <td>Est-ce possible d'aller de Lafarge à Sannois l...</td>\n      <td>Lafarge</td>\n      <td>Sannois</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Les Sables-d'Olonne</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Mon itinéraire prévu est de Trouville-Deauvill...</td>\n      <td>Trouville-Deauville</td>\n      <td>Argentan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Écouflant</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Je traverse Écouflant en me rendant de Gunsbac...</td>\n      <td>Gunsbach-Griesbach</td>\n      <td>Ugine</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Le Toec</td>\n      <td>dimanche</td>\n      <td>23h 37</td>\n      <td>25 mai</td>\n      <td>Je planifie de démarrer de Portets  le dimanch...</td>\n      <td>Portets</td>\n      <td>Nurieux</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"../data/transport_french.json\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df_data, df_data_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:18:27.563223Z",
     "start_time": "2023-12-08T14:18:27.473256Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "('Mon itinéraire prévu est de Bellegarde à Dreuil-lès-Amiens, avec un arrêt à Givors.',\n {'entities': [(28, 38, 'departure'),\n   (41, 58, 'arrival'),\n   (76, 82, 'transit')]})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "\n",
    "for index, row in df_data.iterrows():\n",
    "    sentence = row[\"sentence\"]\n",
    "    departure = row[\"departure\"]\n",
    "    arrival = row[\"arrival\"]\n",
    "    transit = row[\"transit\"]\n",
    "    departure_day = row[\"departure_day\"]\n",
    "    departure_date = row[\"departure_date\"]\n",
    "    departure_time = row[\"departure_time\"]\n",
    "\n",
    "    annotations = {\"entities\": []}\n",
    "\n",
    "    # Define annotations for named entities\n",
    "    if departure:\n",
    "        start_pos = sentence.find(departure)\n",
    "        end_pos = start_pos + len(departure)\n",
    "        annotations[\"entities\"].append((start_pos, end_pos, \"departure\"))\n",
    "\n",
    "    if arrival:\n",
    "        start_pos = sentence.find(arrival)\n",
    "        end_pos = start_pos + len(arrival)\n",
    "        # Check for overlap with existing entities\n",
    "        if not any(start <= start_pos < end or start < end_pos <= end for start, end, _ in annotations[\"entities\"]):\n",
    "            annotations[\"entities\"].append((start_pos, end_pos, \"arrival\"))\n",
    "\n",
    "    if transit:\n",
    "        start_pos = sentence.find(transit)\n",
    "        end_pos = start_pos + len(transit)\n",
    "        if not any(start <= start_pos < end or start < end_pos <= end for start, end, _ in annotations[\"entities\"]):\n",
    "            annotations[\"entities\"].append((start_pos, end_pos, \"transit\"))\n",
    "\n",
    "    if departure_day:\n",
    "        start_pos = sentence.find(departure_day)\n",
    "        end_pos = start_pos + len(departure_day)\n",
    "        annotations[\"entities\"].append((start_pos, end_pos, \"departure_day\"))\n",
    "\n",
    "    if departure_date:\n",
    "        start_pos = sentence.find(departure_date)\n",
    "        end_pos = start_pos + len(departure_date)\n",
    "        annotations[\"entities\"].append((start_pos, end_pos, \"departure_date\"))\n",
    "\n",
    "    if departure_time:\n",
    "        start_pos = sentence.find(departure_time)\n",
    "        end_pos = start_pos + len(departure_time)\n",
    "        annotations[\"entities\"].append((start_pos, end_pos, \"departure_time\"))\n",
    "\n",
    "    train_data.append((sentence, annotations))\n",
    "\n",
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:18:31.113859Z",
     "start_time": "2023-12-08T14:18:30.473489Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    nlp.update([example], drop=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:22:55.722388Z",
     "start_time": "2023-12-08T14:18:36.200338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_path = \"../model/ner_transport_model\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    nlp.to_disk(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:23:42.868522Z",
     "start_time": "2023-12-08T14:23:42.098769Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "my_nlp = spacy.load(\"../model/ner_transport_model\")\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for index, row in df_data_test.iterrows():\n",
    "    my_doc = my_nlp(row[\"sentence\"])\n",
    "    isPredictionTrue = True\n",
    "    for ent in my_doc.ents:\n",
    "        if ent.label_ == \"departure\" and ent.text != row[\"departure\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"arrival\" and ent.text != row[\"arrival\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"transit\" and ent.text != row[\"transit\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"departure_day\" and ent.text != row[\"departure_day\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"departure_date\" and ent.text != row[\"departure_date\"]:\n",
    "            isPredictionTrue = False\n",
    "        elif ent.label_ == \"departure_time\" and ent.text != row[\"departure_time\"]:\n",
    "            isPredictionTrue = False\n",
    "    if isPredictionTrue:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    total_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:28:24.665291Z",
     "start_time": "2023-12-08T14:28:09.628885Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity : mercredi, Label : departure_day\n",
      "Entity : 27 novembre, Label : departure_date\n",
      "Entity : Paris, Label : departure\n",
      "Entity : Marseille, Label : arrival\n",
      "Entity : 9h,, Label : departure_time\n",
      "Entity : Lyon, Label : transit\n"
     ]
    }
   ],
   "source": [
    "my_nlp = spacy.load(\"../model/ner_transport_model\")\n",
    "\n",
    "text = \"le mercredi 27 novembre, je pars de Paris pour Marseille à 9h, en passant par Lyon, \"\n",
    "\n",
    "# Process sample text with the trained model\n",
    "doc = my_nlp(text)\n",
    "\n",
    "# Display named entities in the processed text\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity : {ent.text}, Label : {ent.label_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T14:28:42.513921Z",
     "start_time": "2023-12-08T14:28:40.950246Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
